{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to monitoring answer quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Monitoring LLM systems?\n",
    "\n",
    "As a company, you don't want to be in the headlines for your chatbot gone bad. The creativity that is allowed to LLM's based on the data it has been feed with makes it important to monitor the answers that they give.\n",
    "\n",
    "It is not enoguh to just deploy and hope for he best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring answer quality of LLMs\n",
    "\n",
    "* Compute different types of quality metrics.\n",
    "    * Vector similarity between expected and LLM answer\n",
    "    * LLM-as-a-judge to compute toxicity of LLM answer\n",
    "    * LLM-as-a-judge to assess quality of LLM answer\n",
    "\n",
    "* Store computed metrics in relational database (for example using postgre sql)\n",
    "\n",
    "* Vissualie metrics over time (Grafana may be a good idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Monitoring answer quality with user feedback\n",
    "\n",
    "* Store chat sessions and collect user feedback in database\n",
    "\n",
    "* Use Grafana to visualize user feedback and corresponding chat sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else to monito that is not covered by this module?\n",
    "\n",
    "* Further quality metrics and user feedback\n",
    "* System metrics: Latancy, Traffic, Errors, Saturation\n",
    "* Cost (Ref:magdalenakuhn)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
